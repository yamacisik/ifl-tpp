{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T23:09:46.132064Z",
     "start_time": "2021-07-01T23:09:46.116021Z"
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pickle\n",
    "import torch\n",
    "import torch.utils.data as data_utils\n",
    "\n",
    "from pathlib import Path\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "from data import Sequence,SequenceDataset\n",
    "from model import LogNormMix\n",
    "\n",
    "from copy import deepcopy\n",
    "from util import pad_sequence\n",
    "from torch.distributions import Categorical"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2-D Synth"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T21:45:28.605094Z",
     "start_time": "2021-07-01T21:45:28.540330Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'data/simulated/hawkes_synthetic_random_2d_20191130-180837.pkl'  # run dpp.data.list_datasets() to see the list of available datasets\n",
    "dataset = np.load(dataset_name,allow_pickle = True)\n",
    "\n",
    "## Modify the dataset for IFTPL\n",
    "\n",
    "sequences = []\n",
    "\n",
    "# for i  in range(len(dataset['timestamps'])):\n",
    "for i  in range(400):\n",
    "    sequence = {'t_start':0,'t_end' :200, 'arrival_times':dataset['timestamps'][i].tolist(),'marks' :dataset['types'][i].tolist()}\n",
    "    \n",
    "    sequences.append(sequence)\n",
    "    \n",
    "simulated_data = {'sequences':sequences,'num_marks':2}\n",
    "\n",
    "np.save('data/simulated/sample_hawkes',simulated_data,allow_pickle = True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T00:00:41.107514Z",
     "start_time": "2021-07-02T00:00:40.983794Z"
    }
   },
   "outputs": [],
   "source": [
    "dataset_name = 'data/simulated/hawkes_synthetic_random_2d_20191130-180837.pkl'  # run dpp.data.list_datasets() to see the list of available datasets\n",
    "dataset = np.load(dataset_name,allow_pickle = True)\n",
    "\n",
    "## Modify the dataset for IFTPL\n",
    "\n",
    "sequences = []\n",
    "\n",
    "# for i  in range(len(dataset['timestamps'])):\n",
    "for i  in range(3200):\n",
    "    sequence = {'t_start':0,'t_end' :200, 'arrival_times':dataset['timestamps'][i].tolist(),'marks' :dataset['types'][i].tolist()}\n",
    "\n",
    "    sequences.append(sequence)\n",
    "    \n",
    "simulated_data = {'sequences':sequences,'num_marks':2}\n",
    "\n",
    "with open('data/simulated/train.pkl', 'wb') as handle:\n",
    "    pickle.dump(simulated_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T00:00:52.568170Z",
     "start_time": "2021-07-02T00:00:52.543217Z"
    }
   },
   "outputs": [],
   "source": [
    "## Modify the dataset for IFTPL\n",
    "\n",
    "sequences = []\n",
    "\n",
    "# for i  in range(len(dataset['timestamps'])):\n",
    "for i  in range(3200,3600):\n",
    "    sequence = {'t_start':0,'t_end' :200, 'arrival_times':dataset['timestamps'][i].tolist(),'marks' :dataset['types'][i].tolist()}\n",
    "\n",
    "    sequences.append(sequence)\n",
    "    \n",
    "simulated_data = {'sequences':sequences,'num_marks':2}\n",
    "\n",
    "with open('data/simulated/valid.pkl', 'wb') as handle:\n",
    "    pickle.dump(simulated_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T00:00:58.517312Z",
     "start_time": "2021-07-02T00:00:58.499331Z"
    }
   },
   "outputs": [],
   "source": [
    "## Modify the dataset for IFTPL\n",
    "\n",
    "sequences = []\n",
    "\n",
    "# for i  in range(len(dataset['timestamps'])):\n",
    "for i  in range(3600,4000):\n",
    "    sequence = {'t_start':0,'t_end' :200, 'arrival_times':dataset['timestamps'][i].tolist(),'marks' :dataset['types'][i].tolist()}\n",
    "\n",
    "    sequences.append(sequence)\n",
    "    \n",
    "simulated_data = {'sequences':sequences,'num_marks':2}\n",
    "\n",
    "with open('data/simulated/test.pkl', 'wb') as handle:\n",
    "    pickle.dump(simulated_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T23:29:31.213972Z",
     "start_time": "2021-07-01T23:29:31.192825Z"
    }
   },
   "outputs": [],
   "source": [
    "def convert_sahp_data_format_to_itfl(dataset,num_marks = 2,t_end = 6,t_start = 0):\n",
    "    \n",
    "    dataset \n",
    "    sequences= []\n",
    "    t_max = 0\n",
    "    t_min = 10e10\n",
    "    for i  in range(len(dataset['timestamps'])):\n",
    "        m = max(dataset['timestamps'][i])\n",
    "        mi = min(dataset['timestamps'][i])\n",
    "        if m>t_max:\n",
    "            t_max = m\n",
    "        if mi<t_min:\n",
    "            t_min = mi\n",
    "        sequence = {'t_start':t_start,'t_end' :t_end, 'arrival_times':dataset['timestamps'][i].tolist(),'marks' :dataset['types'][i].tolist()}\n",
    "\n",
    "        sequences.append(sequence)\n",
    "    \n",
    "    itfl_data = {'sequences':sequences,'num_marks':num_marks}\n",
    "    print('T_min:{}, T_max:{} '.format(t_min,t_max))\n",
    "    return itfl_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Stackoverflow"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-02T08:06:24.953176Z",
     "start_time": "2021-07-02T08:06:24.576093Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_min:1325.3760986328125, T_max:1388.5341796875 \n",
      "T_min:1325.3760986328125, T_max:1388.5341796875 \n",
      "T_min:1325.3795166015625, T_max:1388.5323486328125 \n"
     ]
    }
   ],
   "source": [
    "dataset = 'stackoverflow'\n",
    "process_dim =22 \n",
    "\n",
    "train_path = 'data/' + dataset + '/train_manifold_format.pkl'\n",
    "dev_path = 'data/' + dataset + '/dev_manifold_format.pkl'\n",
    "test_path = 'data/' + dataset + '/test_manifold_format.pkl'\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    train_hawkes_data = pickle.load(f)\n",
    "with open(dev_path, 'rb') as f:\n",
    "    dev_hawkes_data = pickle.load(f)\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_hawkes_data = pickle.load(f)\n",
    "\n",
    "    \n",
    "train_data = convert_sahp_data_format_to_itfl(train_hawkes_data,process_dim,t_end = 1390,t_start=1325)\n",
    "dev_data = convert_sahp_data_format_to_itfl(dev_hawkes_data,process_dim,t_end = 1390,t_start=1325)\n",
    "test_data = convert_sahp_data_format_to_itfl(test_hawkes_data,process_dim,t_end = 1390,t_start=1325)\n",
    "\n",
    "\n",
    "with open('data/stackoverflow/test.pkl', 'wb') as handle:\n",
    "    pickle.dump(test_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('data/stackoverflow/valid.pkl', 'wb') as handle:\n",
    "    pickle.dump(dev_data, handle, protocol=pickle.HIGHEST_PROTOCOL)\n",
    "with open('data/stackoverflow/train.pkl', 'wb') as handle:\n",
    "    pickle.dump(train_data, handle, protocol=pickle.HIGHEST_PROTOCOL)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mimic 2\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T23:31:48.849847Z",
     "start_time": "2021-07-01T23:31:48.799806Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_min:0.0, T_max:5.615384578704834 \n",
      "T_min:0.0, T_max:5.884615421295166 \n",
      "T_min:0.0, T_max:5.42307710647583 \n"
     ]
    }
   ],
   "source": [
    "dataset = 'mimic2'\n",
    "process_dim =75 \n",
    "\n",
    "train_path = 'data/' + dataset + '/train_manifold_format.pkl'\n",
    "dev_path = 'data/' + dataset + '/dev_manifold_format.pkl'\n",
    "test_path = 'data/' + dataset + '/test_manifold_format.pkl'\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    train_hawkes_data = pickle.load(f)\n",
    "    \n",
    "with open(dev_path, 'rb') as f:\n",
    "    dev_hawkes_data = pickle.load(f)\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_hawkes_data = pickle.load(f)\n",
    "    \n",
    "    \n",
    "    \n",
    "train_data = convert_sahp_data_format_to_itfl(train_hawkes_data,process_dim,t_end = 6)\n",
    "dev_data = convert_sahp_data_format_to_itfl(dev_hawkes_data,process_dim,t_end = 6)\n",
    "test_data = convert_sahp_data_format_to_itfl(test_hawkes_data,process_dim,t_end = 6)\n",
    "\n",
    "np.save('data/mimic2/train',train_data,allow_pickle = True)\n",
    "np.save('data/mimic2/valid',dev_data,allow_pickle = True)\n",
    "np.save('data/mimic2/test',test_data,allow_pickle = True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Retweet\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2021-07-01T23:33:53.264941Z",
     "start_time": "2021-07-01T23:33:51.822655Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "T_min:1.0, T_max:604798.0 \n",
      "T_min:1.0, T_max:604786.0 \n",
      "T_min:1.0, T_max:604739.0 \n"
     ]
    }
   ],
   "source": [
    "dataset = 'retweet'\n",
    "process_dim =3 \n",
    "\n",
    "train_path = 'data/' + dataset + '/train_manifold_format.pkl'\n",
    "dev_path = 'data/' + dataset + '/dev_manifold_format.pkl'\n",
    "test_path = 'data/' + dataset + '/test_manifold_format.pkl'\n",
    "\n",
    "with open(train_path, 'rb') as f:\n",
    "    train_hawkes_data = pickle.load(f)\n",
    "with open(dev_path, 'rb') as f:\n",
    "    dev_hawkes_data = pickle.load(f)\n",
    "with open(test_path, 'rb') as f:\n",
    "    test_hawkes_data = pickle.load(f)\n",
    "\n",
    "    \n",
    "train_data = convert_sahp_data_format_to_itfl(train_hawkes_data,process_dim,t_end = 604800,t_start=0)\n",
    "dev_data = convert_sahp_data_format_to_itfl(dev_hawkes_data,process_dim,t_end = 604800,t_start=0)\n",
    "test_data = convert_sahp_data_format_to_itfl(test_hawkes_data,process_dim,t_end = 604800,t_start=0)\n",
    "\n",
    "\n",
    "np.save('data/retweet/train',train_data,allow_pickle = True)\n",
    "np.save('data/retweet/valid',dev_data,allow_pickle = True)\n",
    "np.save('data/retweet/test',test_data,allow_pickle = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "latex_envs": {
   "LaTeX_envs_menu_present": true,
   "autoclose": false,
   "autocomplete": true,
   "bibliofile": "biblio.bib",
   "cite_by": "apalike",
   "current_citInitial": 1,
   "eqLabelWithNumbers": true,
   "eqNumInitial": 1,
   "hotkeys": {
    "equation": "Ctrl-E",
    "itemize": "Ctrl-I"
   },
   "labels_anchors": false,
   "latex_user_defs": false,
   "report_style_numbering": false,
   "user_envs_cfg": false
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
